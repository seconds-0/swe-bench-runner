# Dataset Auto-Fetch - Automatic SWE-bench Dataset Loading

**Task ID**: FEAT-Dataset-AutoFetch
**Status**: Completed
**Priority**: High - User Experience Enhancement
**Estimated Effort**: 4-6 hours
**Dependencies**: MVP-BasicOutput-v1 (completed)

## Problem Statement

Currently, users need to:
1. Understand what patches are
2. Create or obtain JSONL files with patches
3. Know the correct format for patches

This is a major barrier to entry. Users should be able to just run:
```bash
# Run specific instances
swebench run --dataset lite --instances django__django-12345,django__django-67890

# Run random 10% of dataset
swebench run --dataset lite --sample 10%

# Run 5 random instances with seed
swebench run --dataset lite --count 5 --random-seed 42

# Run all Django instances using regex
swebench run --dataset lite --subset "django__django-1[0-9]{4}" --regex

# Rerun failed instances from previous run
swebench run --rerun-failed ./results/latest
```

And the tool should automatically fetch and run the requested instances from the SWE-bench dataset.

## Research Phase

### Research Checklist
- [x] How does HuggingFace datasets API work?
- [x] What's the exact structure of SWE-bench datasets on HuggingFace?
- [x] Authentication requirements for HuggingFace API
- [x] Dataset download sizes and caching strategy
- [x] How to extract patches from dataset entries
- [x] Random sampling implementation
- [x] Subset filtering patterns

### Research Findings

#### 1. Dataset Structure (VERIFIED)
- **Available datasets**:
  - `princeton-nlp/SWE-bench_Lite` (300 instances, 1.2MB download)
  - `princeton-nlp/SWE-bench_Verified` (500 instances)
  - `princeton-nlp/SWE-bench` (2294 instances)
- **Key fields**:
  - `instance_id`: e.g., "django__django-12345"
  - `patch`: The actual diff/patch as a string
  - `repo`: e.g., "django/django"
  - `base_commit`: SHA to checkout
  - `problem_statement`: Issue description
  - `test_patch`: Tests added by the PR
- **Split**: All instances are in 'test' split

#### 2. Authentication (VERIFIED)
- **Anonymous access**: ‚úÖ Works for all public SWE-bench datasets
- **No authentication required** for downloading
- **Rate limits**: No explicit limits for dataset downloads
- **Token optional**: Only needed for private datasets

#### 3. Caching (VERIFIED)
- **Default location**: `~/.cache/huggingface/datasets`
- **Size**: SWE-bench_Lite is only 3.6MB on disk
- **Custom cache**: Can set via `HF_DATASETS_CACHE` env var
- **Automatic**: HuggingFace handles download caching

#### 4. Implementation Details (VERIFIED)
- **Loading**: `load_dataset("princeton-nlp/SWE-bench_Lite", split="test")`
- **Filtering**: Works with list comprehension or dataset.filter()
- **Sampling**: Can use dataset.select() with indices
- **Django instances**: 114 out of 300 in Lite dataset

#### 5. Performance Notes
- **All datasets are tiny**: Even full dataset is <20MB
- **No memory concerns**: Load everything, filter in memory
- **Caching works great**: HuggingFace handles it automatically

### Research Tasks (COMPLETED)

#### 1. HuggingFace API Research
```python
# Test script to understand the API
from datasets import load_dataset

# Basic loading
dataset = load_dataset("princeton-nlp/SWE-bench_Lite")
print(f"Dataset info: {dataset}")
print(f"First entry: {dataset['test'][0]}")
print(f"Available fields: {dataset['test'].features}")

# Check download size
print(f"Dataset size: {dataset['test'].info.download_size}")

# Test filtering
django_instances = dataset['test'].filter(lambda x: x['instance_id'].startswith('django__'))
print(f"Django instances: {len(django_instances)}")

# Test random sampling
import random
indices = random.sample(range(len(dataset['test'])), 5)
samples = dataset['test'].select(indices)
```

#### 2. Authentication Research
- HuggingFace token requirements
- Rate limits (anonymous vs authenticated)
- Environment variable conventions (HF_TOKEN)

#### 3. Dataset Structure Research
- Available datasets: SWE-bench_Lite, SWE-bench_Verified, SWE-bench
- Fields in each dataset entry
- How patches are stored (patch field? diff field?)
- Instance ID format and patterns

#### 4. Caching Strategy Research
- HuggingFace datasets default cache location
- How to integrate with our cache directory
- Checksum verification
- Offline mode support

## Proposed Solution

### 1. Core Components

```python
# datasets.py - New module for dataset management
from pathlib import Path
from typing import List, Optional, Dict, Any
import random
from datasets import load_dataset, Dataset
import json

class DatasetManager:
    """Manages SWE-bench dataset downloads and access."""

    DATASET_MAPPING = {
        'lite': 'princeton-nlp/SWE-bench_Lite',
        'verified': 'princeton-nlp/SWE-bench_Verified',
        'full': 'princeton-nlp/SWE-bench'
    }

    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir / "datasets"
        self.cache_dir.mkdir(exist_ok=True)

    def fetch_dataset(self, dataset_name: str, force_download: bool = False) -> Dataset:
        """Fetch dataset from HuggingFace or cache."""
        if dataset_name not in self.DATASET_MAPPING:
            raise ValueError(f"Unknown dataset: {dataset_name}. Choose from: {list(self.DATASET_MAPPING.keys())}")

        hf_dataset_name = self.DATASET_MAPPING[dataset_name]

        # Set cache directory for HuggingFace datasets
        import os
        os.environ['HF_DATASETS_CACHE'] = str(self.cache_dir)

        # Load dataset (will download if not cached)
        dataset = load_dataset(
            hf_dataset_name,
            split='test',  # SWE-bench uses 'test' split
            download_mode='force_redownload' if force_download else 'reuse_dataset_if_exists'
        )

        return dataset

    def get_instances(
        self,
        dataset_name: str,
        count: Optional[int] = None,
        subset_pattern: Optional[str] = None,
        random_seed: Optional[int] = None,
        instances: Optional[List[str]] = None,  # NEW: specific instance IDs
        sample_percent: Optional[float] = None,  # NEW: percentage sampling
        use_regex: bool = False  # NEW: regex support
    ) -> List[Dict[str, Any]]:
        """Get instances from dataset with optional filtering."""
        dataset = self.fetch_dataset(dataset_name)

        # Filter by specific instance IDs first
        if instances:
            dataset = dataset.filter(
                lambda x: x['instance_id'] in instances
            )

        # Apply pattern filtering
        if subset_pattern:
            if use_regex:
                import re
                pattern = re.compile(subset_pattern)
                dataset = dataset.filter(
                    lambda x: pattern.match(x['instance_id']) is not None
                )
            else:
                import fnmatch
                dataset = dataset.filter(
                    lambda x: fnmatch.fnmatch(x['instance_id'], subset_pattern)
                )

        # Handle percentage sampling
        if sample_percent:
            count = int(len(dataset) * sample_percent / 100)
            if count == 0:
                count = 1  # At least one instance

        # Apply random sampling if count specified
        if count and count < len(dataset):
            if random_seed is not None:
                random.seed(random_seed)
            indices = random.sample(range(len(dataset)), count)
            dataset = dataset.select(indices)
        elif count and count >= len(dataset):
            print(f"Warning: Requested {count} instances but dataset only has {len(dataset)}")

        # Convert to list of dicts
        instances = []
        for item in dataset:
            instances.append({
                'instance_id': item['instance_id'],
                'patch': item.get('patch', item.get('diff', '')),  # Handle different field names
                # Include other metadata if needed
                'repo': item.get('repo', ''),
                'base_commit': item.get('base_commit', ''),
                'problem_statement': item.get('problem_statement', '')
            })

        return instances

    def save_as_jsonl(self, instances: List[Dict[str, Any]], output_path: Path) -> None:
        """Save instances as JSONL file for compatibility."""
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w') as f:
            for instance in instances:
                # Only save instance_id and patch for compatibility
                json.dump({
                    'instance_id': instance['instance_id'],
                    'patch': instance['patch']
                }, f)
                f.write('\n')

    def cleanup_temp_files(self) -> None:
        """Clean up all temporary JSONL files."""
        temp_dir = self.cache_dir.parent / "temp"
        if temp_dir.exists():
            import shutil
            shutil.rmtree(temp_dir)
            temp_dir.mkdir()

    def get_dataset_info(self, dataset_name: str) -> Dict[str, Any]:
        """Get information about a dataset without loading it."""
        from datasets import load_dataset_builder

        if dataset_name not in self.DATASET_MAPPING:
            raise ValueError(f"Unknown dataset: {dataset_name}")

        builder = load_dataset_builder(self.DATASET_MAPPING[dataset_name])
        info = builder.info

        return {
            'name': dataset_name,
            'total_instances': info.splits['test'].num_examples,
            'download_size_mb': info.download_size / 1024 / 1024,
            'dataset_size_mb': info.dataset_size / 1024 / 1024,
            'description': info.description
        }
```

### 2. CLI Integration

```python
# Update cli.py run command
@cli.command()
@click.option(
    '-d', '--dataset',
    type=click.Choice(['lite', 'verified', 'full']),
    help='Use SWE-bench dataset (auto-downloads from HuggingFace)'
)
@click.option(
    '--instances',
    help='Comma-separated list of specific instance IDs to run'
)
@click.option(
    '--count',
    type=int,
    help='Number of instances to run (random sample)'
)
@click.option(
    '--sample',
    help='Random percentage of instances (e.g., "10%" or "random-seed=42")'
)
@click.option(
    '--subset',
    help='Filter instances by pattern (e.g., "django__*", "requests__*")'
)
@click.option(
    '--regex',
    is_flag=True,
    help='Treat --subset as regex instead of glob pattern'
)
@click.option(
    '--patches',
    type=click.Path(exists=True),
    help='Path to JSONL file containing patches (alternative to --dataset)'
)
@click.option(
    '--rerun-failed',
    type=click.Path(exists=True),
    help='Rerun failed instances from a previous run directory'
)
def run(dataset, instances, count, sample, subset, regex, patches, rerun_failed, ...):
    """Run SWE-bench evaluation."""

    # Handle --rerun-failed first
    if rerun_failed:
        failed_instances = load_failed_instances(Path(rerun_failed))
        if not failed_instances:
            click.echo("‚úÖ No failed instances to rerun")
            return
        # Convert to instance list
        instances = ','.join(failed_instances)
        click.echo(f"üîÑ Rerunning {len(failed_instances)} failed instances")

    # Priority: explicit patches file > dataset selection
    if not patches and not dataset and not rerun_failed:
        # Try auto-detection
        detected = detect_patches_file()
        if detected:
            patches = detected
            click.echo(f"üí° Using {patches}")
        else:
            click.echo("‚ùå No patches file found. Use --patches or --dataset")
            ctx.exit(1)

    # Handle dataset fetching
    if dataset and not patches:
        from .datasets import DatasetManager

        click.echo(f"üì• Loading {dataset} dataset from HuggingFace...")

        manager = DatasetManager(get_cache_dir())

        # Parse --sample flag
        sample_percent = None
        random_seed = None
        if sample:
            if sample.endswith('%'):
                sample_percent = float(sample[:-1])
            elif '=' in sample:
                # Handle "random-seed=42" format
                parts = sample.split('=')
                if parts[0] == 'random-seed':
                    random_seed = int(parts[1])

        # Parse --instances flag
        instance_list = None
        if instances:
            instance_list = [i.strip() for i in instances.split(',')]

        instances = manager.get_instances(
            dataset_name=dataset,
            instances=instance_list,
            count=count,
            sample_percent=sample_percent,
            subset_pattern=subset,
            use_regex=regex,
            random_seed=random_seed
        )

        if not instances:
            click.echo("‚ùå No instances matched your criteria")
            ctx.exit(1)

        # Save to temporary JSONL for compatibility with existing code
        temp_patches = get_cache_dir() / "temp" / f"{dataset}_{uuid.uuid4().hex[:8]}.jsonl"
        manager.save_as_jsonl(instances, temp_patches)
        patches = temp_patches

        # Clean up old temp files
        manager.cleanup_temp_files()

        click.echo(f"‚úÖ Loaded {len(instances)} instances from {dataset} dataset")
        if instance_list:
            click.echo(f"   Specific instances: {', '.join(instance_list[:3])}{'...' if len(instance_list) > 3 else ''}")
        if sample_percent:
            click.echo(f"   Random {sample_percent}% sample")
        if count:
            click.echo(f"   Limited to {count} instances")
        if subset:
            click.echo(f"   Filtered by {'regex' if regex else 'pattern'}: {subset}")
```

### 3. Helper Functions

```python
# In cli.py or utils.py
def load_failed_instances(results_dir: Path) -> List[str]:
    """Load instance IDs that failed from a previous run."""
    failed_instances = []

    # Check for summary.json files
    for summary_file in results_dir.rglob("summary.json"):
        with open(summary_file) as f:
            data = json.load(f)
            if not data.get('passed', True):
                failed_instances.append(data['instance_id'])

    # Alternative: check for FAILED status files
    if not failed_instances:
        for failed_file in results_dir.rglob("FAILED"):
            instance_id = failed_file.parent.name
            failed_instances.append(instance_id)

    return failed_instances

# Add info command for dataset information
@cli.command()
@click.option(
    '-d', '--dataset',
    type=click.Choice(['lite', 'verified', 'full']),
    required=True,
    help='Dataset to get information about'
)
def info(dataset):
    """Get information about a SWE-bench dataset."""
    from .datasets import DatasetManager

    manager = DatasetManager(get_cache_dir())
    info = manager.get_dataset_info(dataset)

    click.echo(f"\nüìä SWE-bench {dataset} dataset:")
    click.echo(f"   Total instances: {info['total_instances']:,}")
    click.echo(f"   Download size: {info['download_size_mb']:.1f} MB")
    click.echo(f"   On-disk size: {info['dataset_size_mb']:.1f} MB")
    if info['description']:
        click.echo(f"   Description: {info['description'][:100]}...")
```

### 4. Environment Variables & Authentication

```python
# In datasets.py
import os

def get_hf_token() -> Optional[str]:
    """Get HuggingFace token from environment."""
    return os.environ.get('HF_TOKEN') or os.environ.get('HUGGING_FACE_HUB_TOKEN')

def configure_hf_auth():
    """Configure HuggingFace authentication if token available."""
    token = get_hf_token()
    if token:
        from huggingface_hub import login
        login(token=token, add_to_git_credential=False)
        return True
    return False
```

### 5. Error Handling

```python
# Simple, clear error messages
try:
    dataset = load_dataset(...)
except Exception as e:
    if "401" in str(e):
        click.echo("‚ùå Authentication required for this dataset")
        click.echo("   Set HF_TOKEN environment variable with your HuggingFace token")
        click.echo("   Get a token at: https://huggingface.co/settings/tokens")
    elif "Connection" in str(e):
        click.echo("‚ùå Network error downloading dataset")
        click.echo("   Check your internet connection")
    else:
        click.echo(f"‚ùå Failed to load dataset: {e}")
        raise
```

## Implementation Checklist

- [x] Research Phase
  - [x] Test HuggingFace datasets API locally
  - [x] Document exact dataset structure for each variant
  - [x] Test authentication flow
  - [x] Measure download sizes and times
  - [x] Verify patch field names
- [ ] Core Implementation
  - [ ] Create `datasets.py` module
  - [ ] Implement `DatasetManager` class with all methods:
    - [ ] `fetch_dataset()` - simple loading
    - [ ] `get_instances()` with all filtering options
    - [ ] `save_as_jsonl()` with directory creation
    - [ ] `cleanup_temp_files()` - simple cleanup
    - [ ] `get_dataset_info()` for dataset information
  - [ ] Implement all filtering options:
    - [ ] Specific instance IDs (--instances)
    - [ ] Percentage sampling (--sample)
    - [ ] Pattern filtering with glob (--subset)
    - [ ] Regex support (--regex)
    - [ ] Count limiting (--count)

- [ ] CLI Integration
  - [ ] Add all new CLI options:
    - [ ] `-d, --dataset` (short flag support)
    - [ ] `--instances` (comma-separated list)
    - [ ] `--count` (random N instances)
    - [ ] `--sample` (percentage with optional seed)
    - [ ] `--subset` (glob/regex pattern)
    - [ ] `--regex` (flag for regex mode)
    - [ ] `--rerun-failed` (rerun from previous)
  - [ ] Implement `load_failed_instances()` helper
  - [ ] Add `info` command for dataset information
  - [ ] Update run command logic with all options
  - [ ] Maintain backward compatibility with --patches

- [ ] Error Handling
  - [ ] Network errors with retry suggestions
  - [ ] Invalid instance IDs with helpful messages
  - [ ] Pattern matching errors with examples
  - [ ] Clear messaging about what's happening

- [ ] Resource Management
  - [ ] Simple temp file cleanup on start
  - [ ] Let HuggingFace handle caching

- [ ] Testing
  - [ ] Unit tests for DatasetManager
  - [ ] Test all filtering combinations
  - [ ] Test percentage sampling accuracy
  - [ ] Test regex vs glob patterns
  - [ ] Test specific instance selection
  - [ ] Test temp file cleanup
  - [ ] Mock HuggingFace API calls
  - [ ] Integration tests with CLI

- [ ] Documentation
  - [ ] Update README with all dataset examples
  - [ ] Document authentication setup
  - [ ] Add examples to --help text
  - [ ] Add troubleshooting section

## Test Plan

### Unit Tests
```python
def test_dataset_manager_init():
    """Test DatasetManager initialization."""
    manager = DatasetManager(Path("/tmp/test"))
    assert manager.cache_dir.exists()

def test_specific_instances():
    """Test filtering by specific instance IDs."""
    instances = manager.get_instances(
        'lite',
        instances=['django__django-123', 'django__django-456']
    )
    assert len(instances) == 2
    assert all(i['instance_id'] in ['django__django-123', 'django__django-456']
               for i in instances)

def test_percentage_sampling():
    """Test percentage-based sampling."""
    # Test 10% sampling
    instances = manager.get_instances('lite', sample_percent=10.0)
    assert len(instances) == 30  # 10% of 300

def test_regex_filtering():
    """Test regex pattern matching."""
    instances = manager.get_instances(
        'lite',
        subset_pattern=r'django__django-1[0-9]{4}',
        use_regex=True
    )
    assert all(re.match(r'django__django-1[0-9]{4}', i['instance_id'])
               for i in instances)

def test_glob_filtering():
    """Test glob pattern matching."""
    instances = manager.get_instances(
        'lite',
        subset_pattern='django__*',
        use_regex=False
    )
    assert all(i['instance_id'].startswith('django__') for i in instances)

def test_combined_filters():
    """Test combining multiple filters."""
    instances = manager.get_instances(
        'lite',
        subset_pattern='django__*',
        count=5,
        random_seed=42
    )
    assert len(instances) == 5
    assert all(i['instance_id'].startswith('django__') for i in instances)

def test_temp_file_cleanup():
    """Test temporary file cleanup."""
    # Create temp files
    temp_dir = manager.cache_dir.parent / "temp"
    old_file = temp_dir / "old_file.jsonl"
    old_file.touch()

    manager.cleanup_temp_files()
    assert not old_file.exists()
```

### Integration Tests
```python
def test_cli_dataset_option(runner):
    """Test CLI with dataset option."""
    result = runner.invoke(cli, ['run', '-d', 'lite', '--count', '1'])
    assert result.exit_code == 0
    assert "Loading lite dataset" in result.output

def test_cli_specific_instances(runner):
    """Test running specific instances."""
    result = runner.invoke(cli, [
        'run', '-d', 'lite',
        '--instances', 'django__django-123,django__django-456'
    ])
    assert "Specific instances:" in result.output

def test_cli_percentage_sample(runner):
    """Test percentage sampling."""
    result = runner.invoke(cli, ['run', '-d', 'lite', '--sample', '10%'])
    assert "Random 10.0% sample" in result.output

def test_cli_regex_subset(runner):
    """Test regex filtering."""
    result = runner.invoke(cli, [
        'run', '-d', 'lite',
        '--subset', 'django__django-1[0-9]{4}',
        '--regex'
    ])
    assert "Filtered by regex:" in result.output

def test_cli_rerun_failed(runner, tmp_path):
    """Test rerunning failed instances."""
    # Create fake failed results
    failed_dir = tmp_path / "results" / "instance1"
    failed_dir.mkdir(parents=True)
    (failed_dir / "FAILED").touch()

    result = runner.invoke(cli, ['run', '--rerun-failed', str(tmp_path)])
    assert "Rerunning 1 failed instances" in result.output

def test_cli_info_command(runner):
    """Test dataset info command."""
    result = runner.invoke(cli, ['info', '-d', 'lite'])
    assert result.exit_code == 0
    assert "Total instances: 300" in result.output
    assert "Download size:" in result.output
```

## Success Criteria

1. ‚úÖ Users can run `swebench run --dataset lite` without any setup
2. ‚úÖ Users can run specific instances: `swebench run -d lite --instances django__django-123`
3. ‚úÖ Users can run percentage samples: `swebench run -d lite --sample 10%`
4. ‚úÖ Users can filter with regex: `swebench run -d lite --subset "django.*1[0-9]{4}" --regex`
5. ‚úÖ Users can rerun failures: `swebench run --rerun-failed ./results/latest`
6. ‚úÖ Dataset downloads are cached and reused
7. ‚úÖ Random sampling works with reproducible seeds
8. ‚úÖ Subset filtering works with both glob and regex patterns
9. ‚úÖ Clear progress indication during download
10. ‚úÖ Temp files are cleaned up automatically
11. ‚úÖ Helpful error messages for common failures
12. ‚úÖ Works offline if dataset is cached
13. ‚úÖ Maintains compatibility with existing --patches workflow
14. ‚úÖ Short flag `-d` works for dataset selection
15. ‚úÖ Dataset info available via `swebench info -d lite`

## Dependencies

- `datasets` library from HuggingFace
- `huggingface_hub` for authentication
- Existing cache infrastructure
- Internet connection for first download

## Questions/Uncertainties

### Blocking
None - all critical questions have been answered through research.

### Non-blocking
1. **Progress bar integration**: HuggingFace shows its own progress, may need to capture/redirect
2. **Full dataset memory**: Need to verify actual memory usage for 2294 instances
3. **Offline mode detection**: How to gracefully handle when user is offline
4. **Dataset versioning**: Should we pin to specific dataset versions for reproducibility?
5. **Multimodal support**: SWE-bench_Multimodal exists - should we support it?

## Acceptable Tradeoffs

1. **Temporary JSONL files**: Creating temp files maintains compatibility with existing code
2. **Full dataset download**: Can't download individual instances, must get whole dataset
3. **Memory usage**: Loading full dataset into memory is OK for lite/verified

## Implementation Review & Feedback

### Review Summary (Grade: B+ - Good with Reservations)

**Date**: 2025-01-23
**Reviewer**: Claude Code Agent
**Status**: Implementation Complete, Critical Issues Identified

### ‚úÖ Implementation Strengths

**1. Strong Architecture & Separation of Concerns**
- `DatasetManager` class cleanly separates dataset operations from CLI logic
- Clear abstraction layer over HuggingFace datasets API
- Proper error handling with specific exception types
- Good use of dependency injection (cache_dir passed to constructor)

**2. Comprehensive Feature Coverage**
- All planned filtering options implemented (instances, patterns, regex, sampling)
- Excellent CLI ergonomics with short flags (`-d`) and intuitive option names
- Smart defaults and backward compatibility preserved
- Proper exit codes for different error scenarios

**3. Robust Testing Strategy**
- 21 comprehensive tests with good coverage (78% on datasets.py)
- Proper mocking of external dependencies (HuggingFace API)
- Both unit tests (DatasetManager) and integration tests (CLI)
- Tests cover edge cases and error scenarios

**4. User Experience Excellence**
- Clear, actionable error messages with fix suggestions
- Progress indication during downloads (via HuggingFace)
- Smart file cleanup and caching
- Helpful `info` command for dataset exploration

### üö® Critical Issues Identified

**1. Security & Input Validation**
```python
# CRITICAL: No validation of regex patterns - ReDoS vulnerability
pattern = re.compile(subset_pattern)  # User input directly compiled

# CRITICAL: No validation of instance IDs
instances: Optional[List[str]] = None  # Accepts any malformed strings

# RISK: Arbitrary file paths in temp directory
temp_patches = get_cache_dir() / "temp" / f"{dataset}_{uuid.uuid4().hex[:8]}.jsonl"
```

**2. Code Quality Issues**
- Multiple line length violations (>88 chars) - violates project standards
- B904 exceptions should use `raise ... from err` pattern
- Missing type stubs for external libraries causing mypy failures
- Inconsistent variable naming conventions

**3. Resource Management & Race Conditions**
```python
# CRITICAL: Race condition in temp file cleanup
def cleanup_temp_files(self) -> None:
    if temp_dir.exists():
        shutil.rmtree(temp_dir)  # Not atomic
        temp_dir.mkdir(exist_ok=True)  # Race window here
```

**4. Error Handling Fragility**
```python
# FRAGILE: String-based error detection
except Exception as e:
    if "401" in str(e):  # Could break if HuggingFace changes messages
```

**5. CLI Complexity Violation**
- Run command now has 12+ options, violating UX Plan "progressive disclosure"
- Missing magic/smart defaults promised in PRD
- No first-run celebration mentioned in UX Plan

**6. Performance & Scalability Blindspots**
```python
# SCALABILITY: Always loads full dataset into memory
dataset = self.fetch_dataset(dataset_name)
# No streaming support for future large datasets
```

### ‚ö†Ô∏è Missing from Original Requirements

**1. UX Plan Gaps**
- Missing "magic" first-run detection and setup wizard integration
- No dataset auto-selection based on user context
- Missing celebration/success messaging for dataset fetch
- No progressive disclosure implementation

**2. PRD Requirements Not Addressed**
- Offline mode support not implemented
- Resume capability for interrupted downloads missing
- No progress tracking for long-running dataset operations
- Dataset versioning strategy undefined

**3. Architecture Alignment Issues**
- HuggingFace dependency not discussed in Architecture.md
- No failover/backup dataset sources
- Missing integration with existing bootstrap flow

## Detailed Resolution Plan

### Phase 1: Critical Security & Quality Fixes (High Priority - Before Merge)

**Duration**: 2-3 hours
**Blocking**: Yes - must complete before any merge to main

#### Task 1.1: Input Validation & Security
```python
# Add to datasets.py
def _validate_regex_pattern(pattern: str) -> re.Pattern:
    """Validate regex pattern and prevent ReDoS attacks."""
    if len(pattern) > 1000:  # Prevent extremely long patterns
        raise ValueError("Regex pattern too long (max 1000 characters)")

    # Check for common ReDoS patterns
    dangerous_patterns = [
        r'\(\?\=.*\)\+',  # Positive lookahead with quantifier
        r'\(\?\!.*\)\+',  # Negative lookahead with quantifier
        r'.*\*.*\*',      # Nested quantifiers
    ]

    for dangerous in dangerous_patterns:
        if re.search(dangerous, pattern):
            raise ValueError(f"Potentially dangerous regex pattern detected")

    try:
        compiled = re.compile(pattern)
        # Test compilation time
        import time
        start = time.time()
        compiled.match("test")
        if time.time() - start > 0.1:  # 100ms timeout
            raise ValueError("Regex pattern compilation too slow")
        return compiled
    except re.error as e:
        raise ValueError(f"Invalid regex pattern: {e}") from e

def _validate_instance_ids(instance_ids: List[str]) -> List[str]:
    """Validate instance ID format and prevent injection attacks."""
    validated = []
    pattern = re.compile(r'^[a-zA-Z0-9_\-]+__[a-zA-Z0-9_\-]+$')

    for instance_id in instance_ids:
        if len(instance_id) > 200:  # Reasonable limit
            raise ValueError(f"Instance ID too long: {instance_id[:50]}...")

        if not pattern.match(instance_id):
            raise ValueError(f"Invalid instance ID format: {instance_id}")

        # Prevent path traversal
        if '..' in instance_id or '/' in instance_id or '\\' in instance_id:
            raise ValueError(f"Instance ID contains invalid characters: {instance_id}")

        validated.append(instance_id)

    return validated
```

#### Task 1.2: Fix Race Conditions
```python
# Fix cleanup_temp_files() with atomic operations
def cleanup_temp_files(self) -> None:
    """Clean up temporary files with atomic operations."""
    temp_dir = self.cache_dir.parent / "temp"

    # Use exclusive lock to prevent race conditions
    import fcntl
    import tempfile

    lock_file = temp_dir.parent / ".temp_cleanup.lock"

    try:
        with open(lock_file, 'w') as f:
            fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)

            if temp_dir.exists():
                # Create new temp directory first
                new_temp = temp_dir.parent / f"temp_new_{uuid.uuid4().hex[:8]}"
                new_temp.mkdir(exist_ok=True)

                # Atomic rename
                old_temp = temp_dir.parent / f"temp_old_{uuid.uuid4().hex[:8]}"
                temp_dir.rename(old_temp)
                new_temp.rename(temp_dir)

                # Clean up old directory
                shutil.rmtree(old_temp)
            else:
                temp_dir.mkdir(exist_ok=True)

    except (IOError, OSError) as e:
        # Lock failed, another process is cleaning up
        if not temp_dir.exists():
            temp_dir.mkdir(exist_ok=True)
    finally:
        if lock_file.exists():
            lock_file.unlink(missing_ok=True)
```

#### Task 1.3: Code Quality Fixes
- [ ] Fix all line length violations by breaking long strings
- [ ] Add `from err` to all exception re-raises
- [ ] Add type stubs or ignore missing imports in mypy config
- [ ] Standardize variable naming conventions
- [ ] Add docstring examples for all public methods

#### Task 1.4: Error Handling Robustness
```python
# Replace string-based error detection with proper exception hierarchy
class DatasetError(Exception):
    """Base exception for dataset operations."""
    pass

class DatasetAuthenticationError(DatasetError):
    """Authentication required for dataset access."""
    pass

class DatasetNetworkError(DatasetError):
    """Network error during dataset operations."""
    pass

class DatasetNotFoundError(DatasetError):
    """Requested dataset not found."""
    pass

def _classify_huggingface_error(error: Exception) -> DatasetError:
    """Convert HuggingFace errors to our exception hierarchy."""
    error_str = str(error).lower()

    if "401" in error_str or "authentication" in error_str:
        return DatasetAuthenticationError(
            "Authentication required for this dataset. "
            "Set HF_TOKEN environment variable."
        ) from error
    elif "connection" in error_str or "network" in error_str:
        return DatasetNetworkError(
            "Network error downloading dataset. "
            "Check your internet connection."
        ) from error
    elif "not found" in error_str or "404" in error_str:
        return DatasetNotFoundError(
            f"Dataset not found: {error}"
        ) from error
    else:
        return DatasetError(f"Dataset operation failed: {error}") from error
```

### Phase 2: Architecture & Design Improvements (Medium Priority)

**Duration**: 4-6 hours
**Blocking**: No - can be done post-merge

#### Task 2.1: CLI Simplification & Progressive Disclosure
```python
# Group related options into logical clusters
@cli.command()
@click.option('-d', '--dataset', type=click.Choice(['lite', 'verified', 'full']))
@click.option('--patches', type=click.Path(exists=True))
@click.option('--patches-dir', type=click.Path(exists=True, file_okay=False))

# Filtering group (only show when --help-advanced or dataset specified)
@click.option('--instances', help='Specific instance IDs (comma-separated)')
@click.option('--count', type=int, help='Number of random instances')
@click.option('--sample', help='Percentage sample (e.g., "10%")')
@click.option('--subset', help='Pattern filter (e.g., "django__*")')
@click.option('--regex', is_flag=True, help='Use regex patterns')

# Advanced options (hidden by default)
@click.option('--rerun-failed', type=click.Path(exists=True))
@click.option('--max-patch-size', default=5, help='Max patch size in MB')
@click.option('--offline', is_flag=True, help='Use cached data only')
```

#### Task 2.2: Memory Management & Streaming Support
```python
class StreamingDatasetManager(DatasetManager):
    """Memory-efficient dataset manager with streaming support."""

    def get_instances_streaming(
        self,
        dataset_name: str,
        batch_size: int = 100,
        **filters
    ) -> Iterator[List[Dict[str, Any]]]:
        """Stream instances in batches to avoid memory issues."""
        dataset = self.fetch_dataset(dataset_name)

        # Apply filters that don't require full dataset
        if filters.get('instances'):
            dataset = dataset.filter(lambda x: x['instance_id'] in filters['instances'])

        # Stream in batches
        total_size = len(dataset)
        for i in range(0, total_size, batch_size):
            batch = dataset.select(range(i, min(i + batch_size, total_size)))
            yield [self._convert_item(item) for item in batch]

    def estimate_memory_usage(self, dataset_name: str, count: Optional[int] = None) -> float:
        """Estimate memory usage in MB for dataset operations."""
        dataset_info = self.get_dataset_info(dataset_name)

        # Estimate ~1KB per instance on average
        instance_count = count or dataset_info['total_instances']
        estimated_mb = (instance_count * 1024) / (1024 * 1024)  # Convert to MB

        return estimated_mb
```

#### Task 2.3: Enhanced Error Messages & User Guidance
```python
def _get_helpful_error_message(error: DatasetError, context: Dict[str, Any]) -> str:
    """Generate contextual error messages with fix suggestions."""
    if isinstance(error, DatasetAuthenticationError):
        return (
            "‚ùå Authentication required for this dataset\n"
            f"   Dataset: {context.get('dataset', 'unknown')}\n"
            "   \n"
            "   üîß How to fix:\n"
            "   1. Get a free token at: https://huggingface.co/settings/tokens\n"
            "   2. Set environment variable: export HF_TOKEN=your_token_here\n"
            "   3. Or use --hf-token flag: swebench run --hf-token your_token\n"
        )
    elif isinstance(error, DatasetNetworkError):
        return (
            "‚ùå Network error downloading dataset\n"
            "   \n"
            "   üîß How to fix:\n"
            "   1. Check your internet connection\n"
            "   2. Try again in a few minutes (temporary outage)\n"
            "   3. Use --offline flag if dataset is already cached\n"
            f"   4. Check cache status: swebench info -d {context.get('dataset', 'lite')}\n"
        )
    else:
        return str(error)
```

### Phase 3: UX & Integration Enhancements (Lower Priority)

**Duration**: 6-8 hours
**Blocking**: No - V2 features

#### Task 3.1: Magic First-Run Experience
```python
# Integration with existing bootstrap flow
def check_dataset_first_run(dataset_name: str) -> bool:
    """Check if this is first time using dataset features."""
    cache_dir = get_cache_dir()
    marker_file = cache_dir / f".{dataset_name}_downloaded"
    return not marker_file.exists()

def celebrate_dataset_success(dataset_name: str, instance_count: int):
    """Show celebration message for successful dataset fetch."""
    if check_dataset_first_run(dataset_name):
        click.echo()
        click.echo("üéâ Dataset downloaded successfully!")
        click.echo(f"‚ú® You now have access to {instance_count} SWE-bench instances")
        click.echo("üí° Pro tip: Try 'swebench info -d lite' to explore datasets")

        # Mark as completed
        marker_file = get_cache_dir() / f".{dataset_name}_downloaded"
        marker_file.touch()
```

#### Task 3.2: Smart Defaults & Auto-Detection
```python
def detect_user_context() -> Dict[str, Any]:
    """Detect user context for smart defaults."""
    context = {
        'is_first_time': is_first_run(),
        'available_memory_gb': psutil.virtual_memory().total / (1024**3),
        'is_ci': os.environ.get('CI', '').lower() in ('true', '1'),
        'working_directory': Path.cwd(),
    }

    # Suggest dataset based on context
    if context['is_first_time']:
        context['suggested_dataset'] = 'lite'
        context['suggested_count'] = 5
    elif context['available_memory_gb'] < 4:
        context['suggested_dataset'] = 'lite'
        context['suggested_count'] = 10
    else:
        context['suggested_dataset'] = 'verified'
        context['suggested_count'] = 20

    return context

def suggest_smart_defaults(ctx: Dict[str, Any]) -> None:
    """Suggest smart defaults to user."""
    if not any([ctx.get('dataset'), ctx.get('patches'), ctx.get('patches_dir')]):
        click.echo("üí° No patches specified. Would you like me to:")
        click.echo(f"   1. Run {ctx['suggested_count']} instances from {ctx['suggested_dataset']} dataset")
        click.echo("   2. Let you specify options manually")

        if click.confirm("Use smart defaults?", default=True):
            return {
                'dataset': ctx['suggested_dataset'],
                'count': ctx['suggested_count']
            }
```

#### Task 3.3: Offline Mode & Resume Support
```python
def supports_offline_mode(dataset_name: str) -> bool:
    """Check if dataset is available for offline use."""
    cache_dir = get_cache_dir() / "datasets"
    dataset_files = list(cache_dir.glob(f"*{dataset_name}*"))
    return len(dataset_files) > 0

@click.option('--offline', is_flag=True, help='Use cached data only')
def run_with_offline_support(offline: bool, **kwargs):
    """Run evaluation with offline mode support."""
    if offline and not supports_offline_mode(kwargs.get('dataset', 'lite')):
        click.echo("‚ùå Dataset not available offline")
        click.echo("   Run without --offline first to download dataset")
        sys.exit(exit_codes.GENERAL_ERROR)

    # Set environment to prevent network calls
    if offline:
        os.environ['HF_DATASETS_OFFLINE'] = '1'
```

### Phase 4: Documentation & Integration Updates

**Duration**: 2-3 hours
**Blocking**: No - can be done in parallel

#### Task 4.1: Update Architecture Documentation
- [ ] Add section on HuggingFace integration to Architecture.md
- [ ] Document dataset caching strategy and cache management
- [ ] Explain security considerations for user input validation
- [ ] Add dataset dependency management strategy

#### Task 4.2: Update UX Plan Alignment
- [ ] Document how progressive disclosure is implemented
- [ ] Add examples of smart defaults and magic behaviors
- [ ] Update error message catalog with new dataset errors
- [ ] Document offline mode capabilities

#### Task 4.3: Update PRD Success Metrics
- [ ] Add dataset usage metrics and tracking
- [ ] Document performance benchmarks for dataset operations
- [ ] Update time-to-first-success metrics with dataset auto-fetch

### Implementation Timeline & Dependencies

**Week 1: Critical Fixes (Must Complete)**
- Day 1: Security fixes (input validation, race conditions)
- Day 2: Code quality fixes (linting, error handling)
- Day 3: Testing and validation

**Week 2: Architecture Improvements (Should Complete)**
- Day 1-2: CLI simplification and progressive disclosure
- Day 3: Memory management and streaming support
- Day 4: Enhanced error handling

**Week 3: UX Enhancements (Nice to Have)**
- Day 1-2: Magic first-run experience
- Day 3: Smart defaults and auto-detection
- Day 4: Offline mode and resume support

**Ongoing: Documentation Updates**
- Can be done in parallel with implementation
- Should be completed by end of Week 2

### Success Criteria for Resolution

**Phase 1 Complete When**:
- [ ] All linting violations fixed (ruff check passes)
- [ ] All security vulnerabilities addressed (input validation)
- [ ] Race conditions eliminated (atomic file operations)
- [ ] Error handling uses proper exception hierarchy
- [ ] All tests pass with new security measures

**Phase 2 Complete When**:
- [ ] CLI follows progressive disclosure principles
- [ ] Memory usage warnings implemented
- [ ] Streaming support available for large datasets
- [ ] Error messages provide contextual help

**Phase 3 Complete When**:
- [ ] Smart defaults suggest appropriate options
- [ ] First-run experience includes celebration
- [ ] Offline mode works reliably
- [ ] Resume support for interrupted operations

**Overall Success Metrics**:
- User can go from zero to running evaluation in <30 seconds
- No security vulnerabilities in user input handling
- Memory usage scales appropriately with dataset size
- Error recovery rate >90% (users can fix problems themselves)
- Code quality metrics meet project standards

## Notes

- HuggingFace datasets library handles caching automatically
- This feature delivers the "magic" - zero setup evaluation
- Aligns with PRD vision: "Run any subset of SWE-bench with one clear command"
- **CRITICAL**: Must complete Phase 1 before any merge to main branch
- Security fixes are non-negotiable due to user input handling
- Future enhancements:
  - `--offline` flag for airplane mode
  - Streaming mode for very large datasets
  - Support for SWE-bench_Multimodal dataset
  - Dataset version pinning for reproducibility
- The `info` command helps users understand what they're downloading before they commit
